\documentclass[]{report}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}

\usepackage{listings}
\lstset
{
    language=[LaTeX]TeX,
    breaklines=true,
    basicstyle=\tt\scriptsize,
    keywordstyle=\color{blue},
    identifierstyle=\color{magenta},
}

\usepackage{zymacros}

%%%%%%%%%%%%%%%%%%%%%%%
% \NewDocumentCommand{\tens}{t_}
%  {%
%   \IfBooleanTF{#1}
%   {\tensop}
%   {\otimes}%
%  }
% \NewDocumentCommand{\tensop}{m}
%  {%
%   \mathbin{\mathop{\otimes}\displaylimits_{#1}}%
%  }

%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{Mathematical notation protocol for machine learning}
\author{}
\date{\today}
%\begin{abstract}
%\end{abstract}
\maketitle
\begin{abstract}
    This introduces a suggestion of mathematical notation protocol for machine learning.
\end{abstract}

\section{General conceptions}
\begin{center}
    \begin{tabular}{l|l|l|l} 
        \hline
        symbol & meaning & \LaTeX & simplied\\ 
        \hline
        $d$ & input dimension & \verb!d! &  \\
        $d_{\rm out}$ & output dimension & &  \\
        $\vx$ & input & \verb!\bm{x}! & \verb!\vx! \\
        $\vy$ & output, label & \verb!\bm{y}! & \verb!\vy! \\
        $n$ & number of samples & \verb!n!  \\
        $h(\vx)$ & hypothesis function, network output & \verb!h(\bm{x})! & \verb!h(\vx)! \\
        $f(\vx)$ & target function, ground truth & \verb!f(\bm{x})! & \verb!f(\vx)!  \\
        $\{\vx_i\}_{i=1}^n$ 
        & a sequence of $n$ vectors\\
        $x_{i,j}$ 
        & the $j$-th entry of the $i$-th vector in the sequence\\
        $\fX$ 
        & instances domain (a set)\\
        $\fY$ 
        & labels domain (a set)\\
        $\fZ$ 
        & $=\fX\times\fY$ examples domain (a set)\\
        $\fH$ 
        & hypothesis class (a set)\\
        $\ell:\fH\times \fZ\to \sR^+$ & loss function\\
        $\fD$ 
        & a distribution over some set (usually $\fZ$)\\
        $\fD(A)$ 
        & the probability of a set $A\subset \fZ$ according to $\fD$\\
        $z\sim\fD$
        & sampling $z$ according to $\fD$\\
        $S=z_1,\ldots,z_n$
        & a sequence of $n$ examples\\
        $S\sim\fD^n$
        & sampling $S=z_1,\ldots,z_n$ i.i.d. according to $\fD$\\
        $L_{S}=\sum_{z\in S} \ell(h,z)$  & loss of $S$ \\
        $L_{\rm train}$  & training loss \\
        $L_{\rm test}$  & test loss \\
        $\vtheta$  & set of parameters  & & \verb!\vtheta! \\
        $S_{\rm train}$  & training dataset  & &   \\
        $S_{\rm test}$  & test dataset  & &   \\
        
        $\Prob,\Exp$
        & probability and expectation of a random variable\\
        $\Prob_{z\sim\fD}[\rf(z)]$
        & $=\fD(\{z:\rf(z)=\mathrm{true}\})$ for $\rf:\fZ\to\{\mathrm{true},\mathrm{false}\}$\\
        $\Exp_{z\sim\fD}[\rf(z)]$
        & expectation of the random variable $\rf:\fZ\to\sR$\\
        
    \end{tabular}
\end{center}
\end{document}
